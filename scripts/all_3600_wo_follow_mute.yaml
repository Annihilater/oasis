data:
  db_path: "./experiments/results_analysis/all_3600_wo_follow_mute.db"
  user_path: "./data/experiment_dataset/user_data/user_data_3600.json"
  pair_path: "./data/experiment_dataset/agent_3600/all_topics.json"
  exp_info_filename: "./experiments/results_analysis/all_3600_wo_follow_mute.json"
simulation:
  recsys_type: "reddit"
  controllable_user: true
  allow_self_rating: false
  show_score: true
  activate_prob: 0.1
  clock_factor: 10

  num_timesteps: 200
  max_rec_post_len: 300
  round_post_num: 200
  follow_post_agent: False
  mute_post_agent: False
model:
  cfgs:
    - model_type: "llama-3"
      num: 3600
      server_url: "http://10.109.10.49:8080/v1" # eg, http://10.160.2.154:8000/v1
      model_path: "/ibex/user/yangz0h/open_source_llm/llama-3"
      stop_tokens: []
      temperature: 0.0
inference:
  model_type: "llama-3"
  model_path: "LLM-Research/Meta-Llama-3-8B-Instruct"
  stop_tokens: ["<|eot_id|>", "<|end_of_text|>"]
  server_url:
    - host: "10.140.1.173"
      ports: [8002, 8003, 8005, 8006, 8007, 8008, 8011, 8019, 8010, 8014, 8012, 8013, 8017, 8015, 8018]
    - host: "10.140.0.144"
      ports: [8021, 8001, 8027, 8003, 8028, 8025, 8006, 8007, 8008, 8009, 8023, 8011]